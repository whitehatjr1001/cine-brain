#Basic model configuration
BASIC_MODEL:
  model: "llama3.2"
  temperature: 0.2
  base_url: "https://api.groq.com/v1"
  api_key: "$GROQ_API_KEY"  # Read from environment for security
  max_tokens: 6144


# You can keep the others for future use
TOOLS_MODEL:
  model: "llama3.2"
  temperature: 0.2
  base_url: "https://api.groq.com/v1"
  api_key: "$GROQ_API_KEY"
  max_tokens: 2048

PROMPT_MODEL:
  model: "llama3.2"
  temperature: 0.2
  base_url: "https://api.groq.com/v1"
  api_key: "$GROQ_API_KEY"
  max_tokens: 2048

